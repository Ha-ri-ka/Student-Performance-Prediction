{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path=\"D:/StudentPerformance/datasets.csv\"\n",
    "RawData=pd.read_csv(path,delimiter=',')\n",
    "RawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedColumns=['raisedhands','VisITedResources','AnnouncementsView','Discussion','ParentAnsweringSurvey','StudentAbsenceDays','ParentschoolSatisfaction','Class']\n",
    "data=RawData[selectedColumns]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data['StudentAbsenceDays'].unique()\n",
    "data.replace({'Under-7':0,'Above-7':1},inplace=True)\n",
    "data.replace({'No':0,'Yes':1},inplace=True)\n",
    "data.replace({'M':1,'L':0,'H':2},inplace=True)\n",
    "data.replace({'Good':1,'Bad':0},inplace=True)\n",
    "data.replace({'Mum':1,'Father':0},inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random_row=data.sample(n=1).iloc[0, :-1]\n",
    "random_index = random_row.name\n",
    "random_row = np.array(random_row).reshape(1,-1)\n",
    "print(random_index)\n",
    "#16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RawData.info())      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# List of categorical columns to plot\n",
    "categorical_columns = ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', 'Topic', 'Semester', 'Relation']\n",
    "\n",
    "# Set up a grid for subplots\n",
    "num_columns = len(categorical_columns)\n",
    "num_rows = (num_columns + 1) // 2  # Ensure at least 1 row, rounding up\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(10, 3 * num_rows))  # Adjust figsize for smaller graphs\n",
    "\n",
    "# Flatten the 2D array of subplots\n",
    "axes = axes.flatten()\n",
    "\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(x=column, hue='Class', data=RawData, palette={'H': 'lime', 'M': 'grey', 'L': 'red'}, ax=axes[i])\n",
    "    axes[i].set_title(f'Relationship between {column} and Class')\n",
    "    axes[i].tick_params(axis='x', rotation=45)  # Rotate x-axis labels for better visibility\n",
    "\n",
    "\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the columns mentioned above, we can't establish a clear relationship between them and the target variable, we will be removing all these features as they may affect the accuracy. Now let's move on to the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melt = pd.melt(RawData,id_vars='Class',value_vars=['raisedhands','VisITedResources','AnnouncementsView','Discussion'])\n",
    "melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(x='variable',y='value',hue='Class' , data=melt,palette={'H':'lime','M':'grey','L':'red'})\n",
    "plt.ylabel('Values from zero to 100')\n",
    "plt.title('High, middle and low level students')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS YOU CAN SEE THERE'S A CLEAR ESTABLISHMENT OF A RELATION BETWEEN raisedhands,visited resources,announcements view and Discussion with the target Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "\n",
    "\n",
    "sns.countplot(x='StudentAbsenceDays', hue='Class', data=RawData, palette={'H': 'lime', 'M': 'grey', 'L': 'red'}, ax=axes[0])\n",
    "axes[0].set_title('Relationship between StudentAbsent and Class')\n",
    "\n",
    "\n",
    "sns.countplot(x='ParentschoolSatisfaction', hue='Class', data=RawData, palette={'H': 'lime', 'M': 'grey', 'L': 'red'}, ax=axes[1])\n",
    "axes[1].set_title('Relationship between Parent Satisfaction and Class')\n",
    "\n",
    "sns.countplot(x='ParentAnsweringSurvey',hue='Class',data=RawData,palette={'H': 'lime', 'M': 'grey', 'L': 'red'}, ax=axes[2])\n",
    "axes[2].set_title('Relationship between Parent Survey and Class')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS you can see,StudentAbsenceDays is an important feature to select cause it is directly affecting the Class variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logCopy=data.copy()\n",
    "x=logCopy.iloc[:,:-1]\n",
    "y=logCopy.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features=(logCopy.columns.tolist())\n",
    "Features.remove('Class')\n",
    "Target=logCopy['Class']\n",
    "print(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, classification_report, accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52)\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "logiScore = accuracy_score(y_test,y_pred)\n",
    "logiReport = classification_report(y_test,y_pred)\n",
    "Logirmse=pow(mean_squared_error(y_test,y_pred),0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'score={logiScore}')\n",
    "print(f'rmse={Logirmse}')\n",
    "print(logiReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(random_row)\n",
    "print(f\"prediction for randomly selected row: {prediction[0]}\")\n",
    "actualValue=logCopy.iloc[random_index,-1]\n",
    "print(f\"actual value for randomly selected row: {actualValue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Create a scatter plot\n",
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(y_pred)), y_pred, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for LOGISTIC REGRESSION')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTIPLE LINEAR REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLRcopy=data.copy()\n",
    "x=MLRcopy.iloc[:,:-1]\n",
    "y=MLRcopy.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52)\n",
    "model=LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "intercept=model.intercept_\n",
    "coeffs=model.coef_\n",
    "predictions = model.predict(X_test)\n",
    "# Round the predictions to the nearest integer\n",
    "y_pred_mlr = np.round(predictions)\n",
    "mse=mean_squared_error(y_test,y_pred_mlr)\n",
    "MLRrmse= pow(mse,0.5)\n",
    "MLRScore = accuracy_score(y_test,y_pred)\n",
    "MLRReport = classification_report(y_test,y_pred)\n",
    "print(y_pred_mlr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'score={MLRScore}')\n",
    "print(f'rmse={MLRrmse}')\n",
    "print(MLRReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(random_row)\n",
    "print(f\"prediction for randomly selected row: {prediction[0]}\")\n",
    "actualValue=logCopy.iloc[random_index,-1]\n",
    "print(f\"actual value for randomly selected row: {actualValue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Create a scatter plot\n",
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(y_pred_mlr)), y_pred_mlr, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for MULTIPLE LINEAR REGRESSION')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POLYNOMIAL REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyCopy=data.copy()\n",
    "x=MLRcopy.iloc[:,:-1]\n",
    "y=MLRcopy.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def PolynomialRegression(degree,x,y,ipf):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=52)\n",
    "    polyFeatures=PolynomialFeatures(degree)\n",
    "    x_poly=polyFeatures.fit_transform(x_train)\n",
    "    x_test=polyFeatures.fit_transform(x_test)\n",
    "    ipf=polyFeatures.fit_transform(ipf)\n",
    "    model=LinearRegression()\n",
    "    model.fit(x_poly,y_train)\n",
    "    polyPredictions=model.predict(x_test)\n",
    "    y_pred_poly = np.round(polyPredictions)\n",
    "    Ploymse=mean_squared_error(y_test,y_pred_poly)\n",
    "    Polyrmse= pow(Ploymse,0.5)\n",
    "    PolyScore = accuracy_score(y_test,y_pred_poly)\n",
    "    PolyReport = classification_report(y_test,y_pred_poly)\n",
    "    pred=model.predict(ipf)\n",
    "    print(f\"prediction for randomly selected row: {pred[0]}\")\n",
    "    actualValue=logCopy.iloc[random_index,-1]\n",
    "    print(f\"actual value for randomly selected row: {actualValue}\")\n",
    "    print(f'rmse={Polyrmse}')\n",
    "    print(f'score={PolyScore}')\n",
    "    print(PolyReport)\n",
    "    return y_pred_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"USING DEGREE TWO\")\n",
    "deg2=PolynomialRegression(2,x,y,random_row)\n",
    "print(\"-------------------------------\")\n",
    "print(\"USING DEGREE THREE\")\n",
    "deg3=PolynomialRegression(3,x,y,random_row)\n",
    "print(\"-------------------------------\")\n",
    "print(\"USING DEGREE FOUR\")\n",
    "deg4=PolynomialRegression(4,x,y,random_row)\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(deg2)), deg2, label='Predicted', marker='x',c='g',s=30)\n",
    "plt.title('Actual vs. Predicted for poly regression deg2')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(deg3)), deg3, label='Predicted', marker='x',c='g',s=30)\n",
    "plt.title('Actual vs. Predicted for poly regression deg3')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(deg3)), deg3, label='Predicted', marker='x',c='g',s=30)\n",
    "plt.title('Actual vs. Predicted for poly regression deg4')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(scaled, y, test_size=0.2, random_state=52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel=\"linear\",C=100,random_state=42,gamma=1)\n",
    "svc.fit(X_train1,y_train1)\n",
    "svcpred = svc.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(svcpred)), svcpred, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for Support Vector (Linear)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1= SVC(kernel=\"sigmoid\",C=100,random_state=42,gamma=1)\n",
    "svc1.fit(X_train1,y_train1)\n",
    "svcpred1 = svc1.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(svcpred1)), svcpred1, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for Support Vector (Sigmoid)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc2 = SVC(kernel=\"rbf\",C=100,random_state=42,gamma=1)\n",
    "svc2.fit(X_train1,y_train1)\n",
    "svcpred2 = svc2.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(svcpred2)), svcpred2, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for Support Vector (rbf)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test1, svcpred)\n",
    "print(mse)\n",
    "mse1 = mean_squared_error(y_test1, svcpred1)\n",
    "print(mse1)\n",
    "mse2 = mean_squared_error(y_test1, svcpred2)\n",
    "print(mse2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score_svm= accuracy_score(y_test1,svcpred)\n",
    "Score_svm1= accuracy_score(y_test1,svcpred1)\n",
    "Score_svm2= accuracy_score(y_test1,svcpred2)\n",
    "print(Score_svm)\n",
    "print(Score_svm1)\n",
    "print(Score_svm2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector Classifier Linear' + '\\n')\n",
    "print(classification_report(y_test,svcpred))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector Classifier Sigmoid' + '\\n')\n",
    "print(classification_report(y_test,svcpred1))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector Classifier Radial' + '\\n')\n",
    "print(classification_report(y_test,svcpred2))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=7, min_samples_split=4, min_samples_leaf=1, random_state=1)\n",
    "dt.fit(X_train1,y_train1)\n",
    "dtpred = dt.predict(X_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(dtpred)), dtpred, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for Decision Tree Classifier ')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_dt=mean_squared_error(y_test1,dtpred)\n",
    "print(mse_dt)\n",
    "acc_dt=accuracy_score(y_test1,dtpred)\n",
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Desicion Tree Classifier' + '\\n')\n",
    "print(classification_report(y_test,dtpred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Confusion matrix')\n",
    "sns.heatmap(confusion_matrix(y_test,dtpred),cmap='Greens_r',annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3,p=10)\n",
    "knn.fit(X_train1,y_train1)\n",
    "knnpred = knn.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(len(y_test)), y_test, label='Actual', marker='o',c='r',s=40)\n",
    "plt.scatter(np.arange(len(knnpred)), knnpred, label='Predicted', marker='x',c='g',s=30)\n",
    "\n",
    "plt.title('Actual vs. Predicted for KNN ')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Final Grade Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_knn = mean_squared_error(y_test1, knnpred)\n",
    "print(mse_knn)\n",
    "accuracy_knn=accuracy_score(y_test1,knnpred)\n",
    "print(accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K Nearest Neighbours' + '\\n')\n",
    "print(classification_report(y_test,knnpred))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Confusion matrix')\n",
    "sns.heatmap(confusion_matrix(y_test,knnpred),cmap='Oranges_r',annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
